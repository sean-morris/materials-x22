{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb5594",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153556e0",
   "metadata": {},
   "source": [
    "# Lab 5: Climate Change—Temperatures and Precipitation: Part 1: Temperatures\n",
    "\n",
    "In this lab and the next, you will investigate data on climate change, or the long-term shifts in temperatures and weather patterns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff2140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "np.set_printoptions(legacy='1.13')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b00e92",
   "metadata": {},
   "source": [
    "## Part 1: Temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5335a50",
   "metadata": {},
   "source": [
    "In the following analysis, we will investigate one of the 21st century's most prominent issues: climate change. While the details of climate science are beyond the scope of this course, we can start to learn about climate change just by analyzing public records of different cities' temperature and precipitation over time.\n",
    "\n",
    "We will analyze a collection of historical daily temperature and precipitation measurements from weather stations in 210 U.S. cities. The dataset was compiled by Yuchuan Lai and David Dzombak [1]; a description of the data from the original authors and the data itself is available [here](https://kilthub.cmu.edu/articles/dataset/Compiled_daily_temperature_and_precipitation_data_for_the_U_S_cities/7890488). \n",
    "\n",
    "[1] Lai, Yuchuan; Dzombak, David (2019): Compiled historical daily temperature and precipitation data for selected 210 U.S. cities. Carnegie Mellon University. Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7a425",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1, Section 1: Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d584bb",
   "metadata": {},
   "source": [
    "Run the following cell to load information about the `cities` and preview the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = Table.read_table('city_info.csv', index_col=0)\n",
    "cities.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3a882",
   "metadata": {},
   "source": [
    "The `cities` table has one row per weather station and the following columns:\n",
    "\n",
    "1. `\"Name\"`: The name of the US city\n",
    "2. `\"ID\"`: The unique identifier for the US city\n",
    "3. `\"Lat\"`: The latitude of the US city (measured in degrees of latitude)\n",
    "4. `\"Lon\"`: The longitude of the US city (measured in degrees of longitude)\n",
    "4. `\"Stn.Name\"`: The name of the weather station in which the data was collected\n",
    "5. `\"Stn.stDate\"`: A string representing the date of the first recording at that particular station\n",
    "6. `\"Stn.edDate\"`: A string representing the date of the last recording at that particular station\n",
    "\n",
    "The data lists the weather stations at which temperature and precipitation data were collected. Note that although some cities have multiple weather stations, only one is collecting data for that city at any given point in time. Thus, we are able to just focus on the cities themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0e7d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.1:** In the cell below, produce a scatter plot that plots the latitude and longitude of every city in the `cities` table so that the result places northern cities at the top and western cities at the left.\n",
    "\n",
    "*Note*: It's okay to plot the same point multiple times!\n",
    "\n",
    "*Hint*: A latitude is the set of horizontal lines that measures distances *north or south* of the equator. A longitude is the set of vertical lines that measures distances *east or west* of the prime meridian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6eb67",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49306a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "These cities are all within the continental U.S., and so the general shape of the U.S. should be visible in your plot. The shape will appear distorted compared to most maps for two reasons: the scatter plot is square even though the U.S. is wider than it is tall, and this scatter plot is an [equirectangular projection](https://en.wikipedia.org/wiki/Equirectangular_projection) of the spherical Earth. A geographical map of the same data uses the common [Pseudo-Mercator projection](https://en.wikipedia.org/wiki/Web_Mercator_projection).\n",
    "\n",
    "> *Note:* If this visualization doesn't load for you, please view a version of it online [here](https://github.jonathanferrari.com/static/city_map.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28822d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "        lon = cities.column('Lon'),\n",
    "        lat = cities.column('Lat'),\n",
    "        text = cities.column('Name'),\n",
    "        mode = 'markers'))\n",
    "\n",
    "fig.update_layout(geo_scope='usa', width=800, height=500, margin={'r': 0, 't': 0, 'l': 0, 'b': 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72609ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.2** Does it appear that these city locations are sampled uniformly at random from all the locations in the U.S.? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16ab52",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87209b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.3:** Assign `num_unique_cities` to the number of unique cities that appear in the `cities` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2882dae",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "num_unique_cities = ...\n",
    "\n",
    "# Do not change this line\n",
    "print(f\"There are {num_unique_cities} unique cities that appear within our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e5984",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5735d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In order to investigate further, it will be helpful to determine what region of the United States each city was located in: Northeast, Northwest, Southeast, or Southwest. For our purposes, we will be using the following geographical boundaries:\n",
    "\n",
    "<img src= \"usa_coordinates.png\" alt=\"USA Coordinate Map\" width=\"600\"/>\n",
    "\n",
    "1. A station is located in the `\"Northeast\"` region if its latitude is above or equal to 40 degrees and its longtitude is greater than or equal to -100 degrees.\n",
    "2. A station is located in the `\"Northwest\"` region if its latitude is above or equal to 40 degrees and its longtitude is less than -100 degrees.\n",
    "3. A station is located in the `\"Southeast\"` region if its latitude is below 40 degrees and its longtitude is greater than or equal to -100 degrees.\n",
    "4. A station is located in the `\"Southwest\"` region if its latitude is below 40 degrees and its longtitude is less than -100 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685149b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.4**: Define the `coordinates_to_region` function below. It should take in two arguments, a city's latitude (`lat`) and longitude (`lon`) coordinates, and output a string representing the region it is located in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d2eb4",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def coordinates_to_region(...):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb6e22",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e4ccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.5**: Add a new column in `cities` labeled `Region` that contains the region in which the city is located. For full credit, you must use the `coordinates_to_region` function you defined rather than reimplementing its logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a971f7f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "regions_array = ...\n",
    "cities = ...\n",
    "cities.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff96c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9909168b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "To confirm that you've defined your `coordinates_to_region` function correctly and successfully added the `Region` column to the `cities` table, run the following cell. Each region should have a different color in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e65ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "cities.scatter(\"Lon\", \"Lat\", group=\"Region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ec90e",
   "metadata": {},
   "source": [
    "**Challenge Question 1.1.6 <span style=\"color:#BC412B\">(OPTIONAL, ungraded)</span>**: Create a new table called `cities_nearest`. It should contain the same columns as the `cities` table and an additional column called `\"Nearest\"` that contains the **name of the nearest city** that is in a different region from the city described by the row.\n",
    "\n",
    "To approximate the distance between two cities, take the square root of the sum of the squared difference between their latitudes and the square difference between their longitudes. **Don't use a `for` statement; instead, use the `apply` method and array arithmetic.**\n",
    "\n",
    "*Hint*: We have defined a `distance` function for you, which can be called on numbers `lat0` and `lon0` and arrays `lat1` and `lon1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030ed87",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def distance(lat0, lon0, lat1, lon1):\n",
    "    \"Approximate the distance between point (lat0, lon0) and (lat1, lon1) pairs in the arrays.\"\n",
    "    return np.sqrt((lat0 - lat1) * (lat0 - lat1) + (lon0 - lon1) * (lon0 - lon1))\n",
    "\n",
    "...\n",
    "\n",
    "cities_nearest = ...\n",
    "# Note: remove the comment(#) on the next line if you choose to do this question\n",
    "#cities_nearest.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33fb56c",
   "metadata": {},
   "source": [
    "### Part 1, Section 2: Welcome to Phoenix, Arizona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd041cf9",
   "metadata": {},
   "source": [
    "Each city has a different CSV file full of daily temperature and precipitation measurements. The file for Phoenix, Arizona is included with this project as `phoenix.csv`. The files for other cities can be downloaded [here](https://kilthub.cmu.edu/articles/dataset/Compiled_daily_temperature_and_precipitation_data_for_the_U_S_cities/7890488) by matching them to the ID of the city in the `cities` table.\n",
    "\n",
    "Since Phoenix is located on the upper edge of the Sonoran Desert, it has some impressive temperatures.\n",
    "\n",
    "Run the following cell to load in the `phoenix` table. It has one row per day and the following columns:\n",
    "\n",
    "1. `\"Date\"`: The date (a string) representing the date of the recording in **YYYY-MM-DD** format\n",
    "2. `\"tmax\"`: The maximum temperature for the  day (°F)\n",
    "3. `\"tmin\"`: The minimum temperature for the day (°F)\n",
    "4. `\"prcp\"`: The recorded precipitation for the day (inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629778e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenix = Table.read_table(\"phoenix.csv\", index_col=0)\n",
    "phoenix.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ddefd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.1:** Assign the variable `largest_2010_range_date` to the date of the **largest temperature range** in Phoenix, Arizona for any day between January 1st, 2010 and December 31st, 2010. To get started, use the variable `phoenix_with_ranges_2010` to filter the phoenix table to days in 2010 with an additional column corresponding to the temperature range for that day. \n",
    "\n",
    "**Your answer should be a string in the \"YYYY-MM-DD\" format.** Feel free to use as many lines as you need. A temperature range is calculated as the difference between the max and min temperatures for the day.\n",
    "\n",
    "*Hint*: To limit the values in a column to only those that *contain* a certain string, pick the right `are.` predicate from the [Python Reference Sheet](https://www.data8.org/sp24/reference/#table-filtering-predicates).\n",
    "\n",
    "*Note:* Do **not** re-assign the `phoenix` variable; please use the `phoenix_with_ranges_2010` variable instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f80da2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "phoenix_with_ranges_2010 = ...\n",
    "largest_2010_range_date = ...\n",
    "largest_2010_range_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62120ff7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b48bd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "We can look back to our `phoenix` table to check the temperature readings for our `largest_2010_range_date` to see if anything special is going on. Run the cell below to find the row of the `phoenix` table that corresponds to the date we found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "phoenix.where(\"Date\", largest_2010_range_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e592c6",
   "metadata": {},
   "source": [
    "ZOO WEE MAMA! Look at the maximum temperature for that day. That's hot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acd934",
   "metadata": {},
   "source": [
    "The function `extract_year_from_date` takes a date string in the **YYYY-MM-DD** format and returns an integer representing the **year**. The function `extract_month_from_date` takes a date string and returns a string describing the month. Run this cell, but you do not need to understand how this code works or edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "import calendar\n",
    "\n",
    "def extract_year_from_date(date):\n",
    "    \"\"\"Returns an integer corresponding to the year of the input string's date.\"\"\"\n",
    "    return int(date[:4])\n",
    "\n",
    "def extract_month_from_date(date):\n",
    "    \"Return an abbreviation of the name of the month for a string's date.\"\n",
    "    month = date[5:7]\n",
    "    return f'{month} ({calendar.month_abbr[int(date[5:7])]})'\n",
    "\n",
    "\n",
    "# Example\n",
    "print('2022-04-01 has year', extract_year_from_date('2022-04-01'),\n",
    "      'and month', extract_month_from_date('2022-04-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b5c38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.2:** Add two new columns called `Year` and `Month` to the `phoenix` table that contain the year as an **integer** and the month as a **string** (such as `\"04 (Apr)\"`) for each day, respectively. \n",
    "\n",
    "*Note*: The functions above may be helpful!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025deab",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "years_array = ...\n",
    "months_array = ...\n",
    "...\n",
    "phoenix.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88e10e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0913429",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.3:** Using the `phoenix` table, create an overlaid line plot of the **average maximum temperature** and **average minimum temperature** for each year between 1900 and 2020 (inclusive). \n",
    "\n",
    "*Hint:* To draw a line plot with more than one line, call `plot` on the column label of the x-axis values and all other columns will be treated as y-axis values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff3ec2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1d40e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.4:** Although still hotly debated (pun intended), many climate scientists agree that the effects of climate change began to surface in the early 1960s as a result of elevated levels of greenhouse gas emissions. How does the graph you produced in Question 1.2.3 support the claim that modern-day global warming began in the early 1960s? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3da461",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e61196",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Averaging temperatures across an entire year can obscure some effects of climate change. For example, if summers get hotter but winters get colder, the annual average may not change much. Let's investigate how average **monthly** maximum temperatures have changed over time in Phoenix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533b9f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.5:** Create a `monthly_increases` table with one row per month and the following four columns in order: \n",
    "1. `\"Month\"`: The month (such as `\"02 (Feb)\"`)\n",
    "2. `\"Past\"`: The average max temperature in that month from 1900-1960 (both ends inclusive)\n",
    "3. `\"Present\"`: The average max temperature in that month from 2019-2021 (both ends inclusive)\n",
    "4. `\"Increase\"`: The difference between the present and past average max temperatures in that month\n",
    "\n",
    "First, make a copy of the `phoenix` table and add a new column containing the corresponding **period** for each row. The period refers to whether the year is in the `\"Past\"`, `\"Present\"`, or `\"Other\"` category. You may find the period function helpful to see which years correspond to each period. Then, use this new table to construct `monthly_increases`. Feel free to use as many lines as you need.\n",
    "\n",
    "*Hint*: What table method can we use to get each **unique value** as its own column? \n",
    "\n",
    "*Note*: Please do **not** re-assign the `phoenix` variable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071be1b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def period(year):\n",
    "    \"Output if a year is in the Past, Present, or Other.\"\n",
    "    if 1900 <= year <= 1960:\n",
    "        return \"Past\"\n",
    "    elif 2019 <= year <= 2021:\n",
    "        return \"Present\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    \n",
    "...\n",
    "monthly_increases = ...\n",
    "monthly_increases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efe28f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c9ae0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### February in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9dadfd",
   "metadata": {},
   "source": [
    "The `\"Past\"` column values are averaged over many decades, and so they are reliable estimates of the average high temperatures in those months before the effects of modern climate change. However, the `\"Present\"` column is based on only three years of observations. February, the shortest month, has the fewest total observations: only 85 days. Run the following cell to see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a82fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "feb_present = phoenix.where('Year', are.between_or_equal_to(2019, 2021)).where('Month', '02 (Feb)')\n",
    "feb_present.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dc5ac",
   "metadata": {},
   "source": [
    "Look back to your `monthly_increases` table. Compared to the other months, the increase for the month of February is quite small; the February difference is very close to zero. Run the following cell to print out our observed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "print(f\"February Difference: {monthly_increases.row(1).item('Increase')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a180a",
   "metadata": {},
   "source": [
    "Perhaps that small difference is somehow due to chance! To investigate this idea requires a thought experiment.\n",
    "\n",
    "We can observe all of the February maximum temperatures from 2019 to 2021 (the present period), so we have access to the census; there's no random sampling involved. But, we can imagine that if more years pass with the same present-day climate, there would be different but similar maximum temperatures in future February days. From the data we observe, we can try to estimate the **average maximum February temperature** in this imaginary collection of all future February days that would occur in our modern climate, assuming the climate doesn't change any further and many years pass.\n",
    "\n",
    "We can also imagine that the maximum temperature each day is like a **random draw from a distribution of max daily temperatures for that month**. Treating actual observations of natural events as if they were each *randomly* sampled from some unknown distribution is a simplifying assumption. These temperatures were not actually sampled at random—instead they occurred due to the complex interactions of the Earth's climate—but treating them as if they were random abstracts away the details of this naturally occuring process and allows us to carry out statistical inference.  Conclusions are only as valid as the assumptions upon which they rest, but in this case thinking of daily temperatures as random samples from some unknown climate distribution seems at least plausible.\n",
    "\n",
    "If we assume that the **actual temperatures were drawn at random from some large population of possible February days** in our modern climate, then we can not only estimate the population average of this distribution, but also quantify our uncertainty about that estimate using a confidence interval.\n",
    "\n",
    "**We will now compute the confidence interval of the present February average max daily temperature.** To unpack this statement, we are saying that this confidence interval is looking at present-day February conditions (think about which table is relevant to this), and the confidence interval is for present-day February average max daily temperatures. We will compare this confidence interval to the historical average (ie. the `\"Past\"` value in our `monthly_increases` table). How will we do the comparison? Well, since we are essentially interested in seeing if the average February max daily temperatures have ***changed*** since the past, we care about whether the historical average lies within the confidence interval we create. \n",
    "\n",
    "**Based on the information above, think what the null hypothesis and alternative hypothesis are.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ae3fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.6.** Complete the implementation of the function `make_ci`, which takes a one-column table `tbl` containing sample observations and a confidence `level` percentage such as 95 or 99. **It returns an array containing the lower and upper bound in that order, of a confidence interval** for the population mean constructed using 5,000 bootstrap resamples.\n",
    "\n",
    "After defining `make_ci`, we have provided a line of code that calls `make_ci` on the present-day February max temperatures to output the 99% confidence interval for the average of daily max temperatures in February. The result should be around 67 degrees for the lower bound and around 71 degrees for the upper bound of the interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39971a3",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def make_ci(tbl, level):\n",
    "    \"\"\"Compute a level% confidence interval of the average of the population for \n",
    "    which column 0 of Table tbl contains a sample. This function should return an \n",
    "    array of the lower and upper bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "    stats = make_array()\n",
    "    for k in np.arange(5000):\n",
    "        stat = ...\n",
    "        stats = ...\n",
    "    lower_bound = ...\n",
    "    upper_bound = ...\n",
    "    ...\n",
    "\n",
    "# Call make_ci on the max temperatures in present-day February to find the lower and upper bound of a 99% confidence interval.\n",
    "feb_present_ci = make_ci(feb_present.select('tmax'), 99)\n",
    "feb_present_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090f909",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e1fa5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.7** The `feb_present_ci` 99% confidence interval contains the observed past February average maximum temperature of 68.8485 (from the `monthly_increases` table). What conclusion can you draw about the effect of climate change on February maximum temperatures in Phoenix from this information? Use a 1% p-value cutoff.\n",
    "\n",
    "*Note*: If you're stuck on this question, re-reading the paragraphs under the *February* heading (particularly the first few) may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf264bd5",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388610f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### All Months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aacf3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.8.** Repeat the process of seeing whether the **past average for each month** is **contained within the 99% confidence interval** of the **present average**. Just as a note for the context, remember that these “averages” are averages of the max daily temperatures within those time periods. Code has already been written to print out the results in the format of a month (e.g., `02 (Feb)`), the observed past average, the confidence interval for the present average, and whether the past average was contained in the interval or not.\n",
    "\n",
    "Use the provided call to `print` in order to format the result as one line per month.\n",
    "\n",
    "*Hint*: Your code should follow the same format as our code from above (i.e. the *February* section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560736c2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "comparisons = make_array()\n",
    "months = ...\n",
    "for month in months:\n",
    "    past_average = ...\n",
    "    present_observations = ...\n",
    "    present_ci = ...\n",
    "    \n",
    "    # Do not change the code below this line\n",
    "    GREEN_BOLD = '\\033[1;32m'\n",
    "    RED_BOLD = '\\033[1;31m'\n",
    "    RESET_STYLE = '\\033[0m'\n",
    "    within = (past_average >= present_ci.item(0)) and (past_average <= present_ci.item(1))\n",
    "    if within:\n",
    "        comparison = f'{GREEN_BOLD}contained{RESET_STYLE}'\n",
    "    else:\n",
    "        comparison = f'{RED_BOLD}NOT contained{RESET_STYLE}'\n",
    "    comparisons = np.append(comparisons, comparison)\n",
    "    \n",
    "    print('For', month, 'the past avg', round(past_average, 1),\n",
    "    'is', comparison,\n",
    "    'in the interval', np.round(present_ci, 1),\n",
    "    ', the 99% CI of the present avg. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad645ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799940ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.9.** Summarize your findings. After checking whether the past average (of max temperatures, as defined above 1.2.6)  is contained in the 99% confidence interval for each month, what conclusions can we make about the monthly average maximum temperature in historical (1900-1960) vs. modern (2019-2021) times in the twelve months? In other words, what null hypothesis should you consider, and for which months would you reject or fail to reject the null hypothesis? Use a 1% p-value cutoff.\n",
    "\n",
    "*Hint*: Do you notice any seasonal patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6df69",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c868a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "> It is important to be wary of making conclusions based on the results of multiple hypothesis tests. Specifically, recall that a 1% p-value cutoff means that if the null is true, we would expect to incorrectly reject the null 1% of the time. Now, if we run multiple of these tests, the chance we observe an error will be greater than if we had just run one test – the error chance compounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77270b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15198c5e",
   "metadata": {},
   "source": [
    "## Finishing up\n",
    "\n",
    "**Important submission information:** \n",
    "- Be sure to run the tests and verify that they all pass by running the `grader.check_all()` cell below,\n",
    "- Save your progress by choosing the **Save and Checkpoint** item in the **File** menu, \n",
    "- Submit your work by clicking the **Submit** button in the toolbar at the top of notebook. \n",
    "- Download a zip file of this notebook by running the last cell below. **Note:** Be sure to run all the tests before exporting so that all images/graphs appear in the exported notebook. \n",
    "\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To double-check your work, the cell below will rerun all of the autograder tests.\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65181fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0c602",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867e8d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d583b0c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b324e0b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460d9d5",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1_3": {
     "name": "q1_1_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(num_unique_cities) in set([int, np.int32, np.int64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> num_unique_cities > 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1_4": {
     "name": "q1_1_4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(coordinates_to_region(50, 100)) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1_5": {
     "name": "q1_1_5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(cities.labels) == 8\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cities.labels[-1] == 'Region'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cities.row(0).item('Region') == 'Northwest'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_1": {
     "name": "q1_2_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(largest_2010_range_date) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_2": {
     "name": "q1_2_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> phoenix.num_rows == 46021\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(phoenix.labels) == 6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> phoenix.labels == ('Date', 'tmax', 'tmin', 'prcp', 'Year', 'Month')\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_5": {
     "name": "q1_2_5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> monthly_increases.num_rows == 12\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> monthly_increases.labels == ('Month', 'Past', 'Present', 'Increase')\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> monthly_increases.row(2).item('Month') == '03 (Mar)'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_6": {
     "name": "q1_2_6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 66.6 <= feb_present_ci.item(0) <= 67.3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 71 <= feb_present_ci.item(1) <= 72\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_8": {
     "name": "q1_2_8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(months) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "otter_service": {
   "assignment": "lab05",
   "course": "8x",
   "section": "2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
